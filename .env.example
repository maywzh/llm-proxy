# LLM Proxy Environment Variables Template
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control!

# API Keys for each provider
API_KEY_0=your-api-key-0-here
API_KEY_1=your-api-key-1-here
API_KEY_2=your-api-key-2-here
API_KEY_3=your-api-key-3-here

# API Base URL (shared by all providers)
API_BASE_URL=https://inference.bottlerocket.tesla.com/models/claude-4/v1

# Model ARNs
MODEL_ARN_SONNET_45=arn:aws:bedrock:us-east-1:603947095197:application-inference-profile/24quy30gs8jc
MODEL_ARN_HAIKU_45=arn:aws:bedrock:us-east-1:603947095197:application-inference-profile/63ybopyqov8m
MODEL_ARN_OPUS_41=arn:aws:bedrock:us-east-1:603947095197:application-inference-profile/c1hq7ugb2v6j
MODEL_ARN_OPUS_4=arn:aws:bedrock:us-east-1:603947095197:application-inference-profile/jcugtwf9ktzo
MODEL_ARN_SONNET_4=arn:aws:bedrock:us-east-1:603947095197:application-inference-profile/474hi74eqmoc

# Server Configuration
HOST=0.0.0.0
PORT=18000
MASTER_API_KEY=sk-your-master-key-here

# SSL Configuration
VERIFY_SSL=false


GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin