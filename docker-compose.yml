version: '3.8'

services:
  llm-proxy:
    build: .
    container_name: llm-proxy
    ports:
      - "18000:18000"
    volumes:
      # Mount external config file (optional, uses default if not provided)
      - ./config.yaml:/app/config.yaml:ro
      # Mount external certificate file (optional)
      - ./cacerts.pem:/app/cacerts.pem:ro
    environment:
      - PYTHONUNBUFFERED=1
      # Specify config file path (default: /app/config.yaml)
      - CONFIG_PATH=/app/config.yaml
      # Specify server host (default: 0.0.0.0)
      - HOST=0.0.0.0
      # Specify server port (default: 18000)
      - PORT=18000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
